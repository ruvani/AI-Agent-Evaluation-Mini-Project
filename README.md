## Agent Evaluation Framework

A minimal, fully runnable framework for evaluating AI agents using layered metrics.

This project demonstrates how to evaluate autonomous agents across:

- Task completion
- Reasoning alignment
- Tool usage validation
- Execution latency
- Aggregated scoring

## Overview

Traditional model evaluation focuses only on the final output.

Agent systems require deeper evaluation because they:

- Use tools
- Maintain reasoning traces
- Execute actions
- Operate across multiple steps

This framework evaluates the full execution loop using structured logs and layered scoring.
